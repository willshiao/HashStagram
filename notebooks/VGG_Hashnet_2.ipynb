{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from os import path\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms, utils\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "PATH = '/shared/HARRISON'\n",
    "MODEL_PATH = 'vgg_hashnet_r3_v6.pth'\n",
    "pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VGG_HASHNET(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG_HASHNET, self).__init__()\n",
    "        self.object_extractor = models.vgg16(pretrained=True)\n",
    "        self.object_extractor.classifier = nn.Sequential(*list(self.object_extractor.classifier.children())[:-2])\n",
    "        self.object_extractor.eval()\n",
    "\n",
    "        self.background_extractor = models.__dict__['alexnet'](num_classes=365)\n",
    "        checkpoint = torch.load('/shared/alexnet_places365.pth.tar', map_location=lambda storage, loc: storage)\n",
    "        state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "        self.background_extractor.load_state_dict(state_dict)\n",
    "        self.background_extractor.classifier = nn.Sequential(*list(self.background_extractor.classifier.children())[:-1])\n",
    "        self.background_extractor.eval()\n",
    "\n",
    "        self.fc1 = nn.Linear(4096 * 2, 4096)\n",
    "#         self.fc1 = nn.DataParallel(self.fc1)\n",
    "        self.fc2 = nn.Linear(4096,4096)\n",
    "#         self.fc2 = nn.DataParallel(self.fc2)\n",
    "\n",
    "        self.output = nn.Linear(4096,997)\n",
    "        if pretrained:\n",
    "            loaded = torch.load(MODEL_PATH)\n",
    "            self.load_state_dict({ str.replace(k,'module.', ''): v for k,v in loaded.items() })\n",
    "#         print(self.object_extractor)\n",
    "#         print(\"============================\")\n",
    "#         print(self.background_extractor)\n",
    "    def forward(self, x):\n",
    "        obj_feat = self.object_extractor(x)\n",
    "#         print(obj_feat.size())\n",
    "        scene_feat = self.background_extractor(x)\n",
    "#         print(scene_feat.size())\n",
    "        feats = torch.cat((obj_feat, scene_feat), dim=1)\n",
    "#         print(feats.size())\n",
    "        output = self.fc1(feats)\n",
    "        output = self.fc2(output)\n",
    "        output = self.output(output)\n",
    "#         print('Layer:', output)\n",
    "        return torch.sigmoid(output)\n",
    "model = VGG_HASHNET()\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)\n",
    "# model.load_state_dict(weight_dict)\n",
    "# torch.save(model.state_dict(), \"./TEHBESTMODEL.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARRISON_DATASET(Dataset):\n",
    "    def __init__(self):\n",
    "        # reading either data or image labels, filepaths\n",
    "        #read data_list\n",
    "        with open(path.join(PATH, 'data_list.txt')) as f:\n",
    "            self.images = [l.strip() for l in f.readlines()]\n",
    "#         print('SELF IMAGES: {}'.format(self.images[0]))\n",
    "\n",
    "        # read hashtags\n",
    "        with open(path.join(PATH, 'tag_list.txt')) as f:\n",
    "            self.tags = [l.strip() for l in f.readlines()]\n",
    "\n",
    "        self.tags = [x.split(' ') for x in self.tags]\n",
    "#         print(self.tags)\n",
    "        self.word_map = {}\n",
    "        curr_size = 0\n",
    "\n",
    "        for labels in self.tags:\n",
    "            for tag in labels:\n",
    "                if tag not in self.word_map:\n",
    "                    self.word_map[tag] = curr_size\n",
    "                    curr_size += 1\n",
    "\n",
    "        self.num_labels = len(self.word_map.keys())\n",
    "        self.tags = [self._convert_onehot(x) for x in self.tags]\n",
    "\n",
    "        self.normalize = transforms.Normalize(\n",
    "           mean=[0.485, 0.456, 0.406],\n",
    "           std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        self.preprocess = transforms.Compose([\n",
    "           transforms.Resize(224),\n",
    "           transforms.CenterCrop(224),\n",
    "           transforms.ToTensor(),\n",
    "           self.normalize\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         print(self.word_map)\n",
    "        #read_file from disk\n",
    "        img_path = os.path.join(PATH, self.images[index])\n",
    "        img = Image.open(img_path)\n",
    "        img_tensor = self.preprocess(img).cuda()\n",
    "        return(img_tensor, self.tags[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def _convert_onehot(self, tags):\n",
    "        one_hot = np.zeros(self.num_labels, dtype=np.float32)\n",
    "        for tag in tags:\n",
    "            one_hot[self.word_map[tag]] = 1\n",
    "        return torch.from_numpy(one_hot).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "dset = HARRISON_DATASET()\n",
    "batch_size = 72\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "\n",
    "dataset_size = len(dset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "random_seed = 42\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dset,\n",
    "                                                batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=1.1)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.004, momentum=1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.7)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "EPOCHS = 50\n",
    "\n",
    "def get_intersection(a, b):\n",
    "    a = a.cpu()\n",
    "    b = b.cpu()\n",
    "#     print(a,b)\n",
    "\n",
    "    values_output, idx_output = torch.topk(a, 5)\n",
    "    values_label, idx_labels = torch.topk(b, 5)\n",
    "\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    for i in range(len(idx_output)):\n",
    "    #     print(idx_output[i], idx_labels[i])\n",
    "        intersection = np.intersect1d(idx_output[i].numpy(), idx_labels[i].numpy())\n",
    "        accuracy.append(min(len(intersection), 1))\n",
    "\n",
    "#         print(idx_output[i], idx_labels[i])\n",
    "        intersection = [x for x in intersection if b[i].numpy()[x] > 0]\n",
    "        unique, counts = np.unique(intersection, return_counts=True)\n",
    "        int_count = len(counts[counts > 0])\n",
    "        precision.append(int_count / 5)\n",
    "        \n",
    "        \n",
    "        np_values_label = values_label[i].numpy()\n",
    "        recall.append(int_count / len(np_values_label[np_values_label > 0]))\n",
    "#         input()\n",
    "        if(recall[-1] > 1):\n",
    "            print(idx_output[i], idx_labels[i])\n",
    "            print(int_count)\n",
    "            print(intersection)\n",
    "            print(len(values_label[i].numpy()[np.where(values_label[i].numpy() > 0)]))\n",
    "            print(values_output[i], values_label[i])\n",
    "            print(precision[-1])\n",
    "            input()\n",
    "    return (precision, recall, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "BATCHES = 100\n",
    "previous_lr = 0.0\n",
    "break_out = False\n",
    "\n",
    "for ep in tqdm(range(EPOCHS)):\n",
    "    if break_out:\n",
    "        print('Breaking out!')\n",
    "        break\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_precision = 0.0\n",
    "    running_recall = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "#         print('Labels: {}'.format(labels))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward + back + opt3\n",
    "        outputs = model.forward(inputs)\n",
    "        \n",
    "        precision, recall, accuracy = get_intersection(outputs, labels)\n",
    "        total_predictions += len(precision)\n",
    "        \n",
    "        running_precision += sum(precision)\n",
    "        running_recall += sum(recall)\n",
    "        running_accuracy += sum(accuracy)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % BATCHES == (BATCHES-1):    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.4f | precision: %.4f | recall: %.4f | accuracy: %.4f' %\n",
    "                  (ep + 1, i + 1, running_loss / BATCHES, running_precision / total_predictions, \n",
    "                  running_recall / total_predictions, running_accuracy / total_predictions))\n",
    "            if abs(running_loss - previous_lr)/running_loss < 0.001:\n",
    "                break_out = True\n",
    "                break\n",
    "            previous_lr = running_loss\n",
    "            running_loss = 0.0\n",
    "            running_recall = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            running_precision = 0.0\n",
    "            total_predictions = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model (optional)\n",
    "# torch.save(model.state_dict(), 'vgg_hashnet_r3_v6.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f293a6edf6452c82f08ae94b3a4828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bench_loss = 0.0\n",
    "bench_precision = 0.0\n",
    "bench_recall = 0.0\n",
    "bench_accuracy = 0.0\n",
    "bench_total_predictions = 0\n",
    "\n",
    "for i, data in tqdm(enumerate(validation_loader, 0)):\n",
    "    inputs, labels = data\n",
    "    outputs = model.forward(inputs)\n",
    "    \n",
    "    precision, recall, accuracy = get_intersection(outputs, labels)\n",
    "    bench_total_predictions += len(precision)\n",
    "        \n",
    "    bench_precision += sum(precision)\n",
    "    bench_recall += sum(recall)\n",
    "    bench_accuracy += sum(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall results: \n",
      "# of samples: 11476\n",
      "Precision @ 5: 0.141774\n",
      "Recall @ 5: 0.233670\n",
      "Accuracy: 0.537034\n"
     ]
    }
   ],
   "source": [
    "print('Overall results: ')\n",
    "print('# of samples: {}'.format(bench_total_predictions))\n",
    "print('Precision @ 5: {:4f}'.format(bench_precision / bench_total_predictions))\n",
    "print('Recall @ 5: {:4f}'.format(bench_recall / bench_total_predictions))\n",
    "print('Accuracy: {:4f}'.format(bench_accuracy / bench_total_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torchvision.utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    img = img.cpu()\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(validation_loader)\n",
    "images, labels = dataiter.next()\n",
    "classes = dset.word_map\n",
    "classes = {val:key for (key, val) in classes.items()}\n",
    "# classes[123]\n",
    "print(images.size())\n",
    "\n",
    "    # print images\n",
    "    # print(output)\n",
    "    # print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "    # output = model(images)\n",
    "    # _, predicted = torch.max(outputs, 5)\n",
    "    # print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "    # for j in range(4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(images[0:2])\n",
    "print(torch.topk(output,5))\n",
    "imshow(images[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.topk(output, 5)[-1].cpu().numpy()[-2]\n",
    "print(results)\n",
    "for i in results:\n",
    "    print(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
